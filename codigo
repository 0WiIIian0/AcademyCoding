import bs4
import urllib.request
from urllib.request import urlopen
from bs4 import BeautifulSoup as soup

#vai para a página da web e coletar dados

html = urlopen('https://en.wikipedia.org/wiki/List_of_largest_recorded_music_markets') 
#leitura do site carregado
bsobj = soup(html.read())
tbody = bsobj('table',{'class':'wikitable plainrowheaders sortable'})[3].findAll('tr')
xl = []
for row in tbody:
    cols = row.findChildren(recursive = False)
    cols = tuple(element.text.strip().replace('%','') for element in cols)
    xl.append(cols)
xl = xl[1:-1]
xl

#instalando o modulo pyodbc para se conectar ao banco de dados SQL server
import pyodbc 

def retorna_conexao():
    server = "DESKTOP-0EC1IM3"
    database = "AcademyCoding"
#username = “Nome do username”
#password = “Senha”

#string_conexao = ‘Driver={SQL Server Native Client 11.0};Server=’+server+’;Database=’+database+’;UID=’+username+’;PWD=’+password
    string_conexao = 'Driver={SQL Server Native Client 11.0};Server='+server+';Database='+database+';Trusted_Connection=yes;'

#Abrindo a conexão com o banco de dados pyodbc
    
    return pyodbc.connect(string_conexao)
    
    cursor = retorna_conexao().cursor()



# Drop table if it already exist using execute() method.
#Elimine a tabela se ela já existir usando o método execute ().

#cursor.execute("DROP TABLE IF EXISTS WIKI ")



# Create table as per requirement
#Criando table por requerimento

sql = """create table wiki (
  RANKINGINT int,
  MARKET char(50),
  RETAIL_VALUE char(20),
  PHYSICAL int,
  DIGITAL int,
  PERFORMANCE_RIGHTS int,
  SYNCHRONIZATION int
 )"""

cursor.execute(sql)

retorna_conexao().close()
cursor.close()

#Save data to the table
#Salvando os dados na tabela

#scrap_db = pymysql.connect(h,u,p,db)
scrap_db = pyodbc.connect(string_conexao)
SqlServer_insert_query = """INSERT INTO WIKI (RANKING, MARKET, RETAIL_VALUE, PHYSICAL,DIGITAL,PERFORMANCE_RIGHTS,SYNCHRONIZATION) 
VALUES (%s, %s, %s, %s ,%s, %s, %s) """

records_to_insert = xl

cursor = scrap_db.cursor()
cursor.executemany(SqlServer_insert_query, records_to_insert)
scrap_db.commit()
print(cursor.rowcount, "Record inserted successfully into WIKI2 table")


# disconnect from server
#desconectado do server
scrap_db.close()

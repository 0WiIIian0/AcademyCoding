import bs4
import urllib.request
from urllib.request import urlopen
from bs4 import BeautifulSoup as soup

#vai para a página da web e coletar dados

html = urlopen('https://en.wikipedia.org/wiki/List_of_largest_recorded_music_markets') 
#leitura do site carregado
bsobj = soup(html.read())
tbody = bsobj('table',{'class':'wikitable plainrowheaders sortable'})[3].findAll('tr')
xl = []
for row in tbody:
    cols = row.findChildren(recursive = False)
    cols = tuple(element.text.strip().replace('%','') for element in cols)
    xl.append(cols)
xl = xl[1:-1] #tira a primeira e ultima linha
xl

#Conectando com o banco de dados
import mysql.connector

bd = mysql.connector.connect(
    host="localhost",
    user="teste",
    passwd="teste",
    database="academycoding"
)

cursor = bd.cursor()


#Elimine a tabela se ela já existir usando o método execute ().

cursor.execute("DROP TABLE IF EXISTS WIKI ")


#Criando table por requerimento

sql = """create table wiki (
  RANKING int,
  MARKET char(50),
  RETAIL_VALUE char(20),
  PHYSICAL int,
  DIGITAL int,
  PERFORMANCE_RIGHTS int,
  SYNCHRONIZATION int
 )"""

cursor.execute(sql)

#fechando o cursor
cursor.close()
#desconectando do banco
bd.close()


#Salvando os dados na tabela

bd = mysql.connector.connect(
    host="localhost",
    user="teste",
    passwd="teste",
    database="academycoding"
)
MySql_insert_query = """INSERT INTO WIKI (RANKING, MARKET, RETAIL_VALUE, PHYSICAL,DIGITAL,PERFORMANCE_RIGHTS,SYNCHRONIZATION) 
VALUES (%s, %s, %s, %s ,%s, %s, %s) """

records_to_insert = xl

cursor = bd.cursor()
cursor.executemany(MySql_insert_query, records_to_insert)
bd.commit()
print(cursor.rowcount, "Foi gravado com sucesso na tabela wiki!")

#fechando o cursor
cursor.close()
#desconectado do banco
bd.close()
